import os
import json
import unicodedata
import gc
import multiprocessing as mp
from dataclasses import dataclass
from pathlib import Path
from difflib import SequenceMatcher
from concurrent.futures import ProcessPoolExecutor, as_completed
import base64
import psutil

import numpy as np
import cv2
from decord import VideoReader, cpu
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from httpx import Client

proc = psutil.Process(os.getpid())

@dataclass
class PlaylistItem:
    index: int
    title: str
    video_path: str

def normalized(text):
    if text is None:
        return ""

    s = text.strip()
    s = s.replace('\n', ' ').replace('\r', ' ')
    s = " ".join(s.split())
    s = s.lower()
    s = s.replace(' - ', '-')

    s = unicodedata.normalize('NFD', s)
    s = ''.join(char for char in s if unicodedata.category(char) != 'Mn')

    return s


def similarity(a, b):
    return SequenceMatcher(None, a, b).ratio()

def is_similar_text(a, b, sim_threshold=0.85):
    na, nb = normalized(a), normalized(b)
    if na == "" and nb == "":
        return True
    sim = similarity(na, nb)
    return sim >= sim_threshold


def numpy_to_base64(img: np.ndarray) -> str:
    _, buffer = cv2.imencode(".png", img)
    img_bytes = buffer.tobytes()
    img_b64 = base64.b64encode(img_bytes).decode("utf-8")
    return img_b64


def create_llm(temperature=0.0):
    """T·∫°o LLM client m·ªõi (d√πng trong m·ªói process)"""
    http_client = Client(verify=False)
    llm = ChatOpenAI(
        model="Qwen/Qwen2.5-VL-3B-Instruct",
        openai_api_base=os.getenv("OPENAI_API_BASE", "http://localhost:8233/v1"),
        openai_api_key="your_api_key",
        http_client=http_client,
        temperature=temperature,
    )
    return llm, http_client


class VideoOCRProcessor:
    def __init__(self, video_path: str, crop=(100, 530, 1200, 680)):
        self.video_path = video_path
        self.crop = crop
        self.vr = VideoReader(video_path, ctx=cpu(0))
        self.total_frames = len(self.vr)
        self.video_fps = float(self.vr.get_avg_fps())
        self.ocr_calls = 0
        self.ocr_cache = {}
        self._llm, self._http_client = create_llm()
    
    def cleanup(self):
        self.ocr_cache.clear()
        
        # ƒê√≥ng httpx client
        if hasattr(self, '_http_client') and self._http_client:
            try:
                self._http_client.close()
            except:
                pass
        
        # X√≥a LLM
        if hasattr(self, '_llm'):
            del self._llm
        
        if hasattr(self, 'vr'):
            try:
                self.vr.seek(0)  # Reset position
            except:
                pass
            del self.vr
            gc.collect()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()
        return False

    def read_frame(self, time_point: float):
        frame_index = int(time_point * self.video_fps) + 1
        frame_index = min(frame_index, self.total_frames - 1)

        if frame_index < 0 or frame_index >= self.total_frames:
            return None

        frame = self.vr[frame_index].asnumpy()
        x1, y1, x2, y2 = self.crop
        return frame[y1:y2, x1:x2]

    def ocr(self, frame_time: float):
        if frame_time in self.ocr_cache:
            return self.ocr_cache[frame_time]

        frame = self.read_frame(frame_time)
        if frame is None:
            return ""

        self.ocr_calls += 1
        img_b64 = numpy_to_base64(frame)

        message = HumanMessage(
            content=[
                {
                    "type": "text",
                    "text": "H√£y ƒë·ªçc OCR trong ·∫£nh n√†y, tr·∫£ v·ªÅ text ƒë√∫ng nh·∫•t. Ch·ªâ tr·∫£ v·ªÅ text, kh√¥ng gi·∫£i th√≠ch th√™m. N·∫øu trong ·∫£nh kh√¥ng c√≥ text ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ocr th√¨ tr·∫£ v·ªÅ \"\". N·∫øu trong ·∫£nh c√≥ ph·∫ßn b·∫£ng t√™n c·ªßa ng∆∞·ªùi ph·ªèng v·∫•n th√¨ c≈©ng kh√¥ng tr·∫£ v·ªÅ text ·ªü trong ƒë√≥.",
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{img_b64}"},
                },
            ]
        )

        response = self._llm.invoke([message])
        text = response.content
        self.ocr_cache[frame_time] = text
        return text

    def binary_segmentation(self, left_time, right_time, left_text=None, right_text=None, threshold=0.5, sim_threshold=0.9):
        """Ph√¢n ƒëo·∫°n nh·ªã ph√¢n ƒë·ªÉ t√¨m ƒëi·ªÉm chuy·ªÉn text"""
        if left_text is None:
            left_text = self.ocr(left_time)
        if right_text is None:
            right_text = self.ocr(right_time)

        if is_similar_text(left_text, right_text, sim_threshold):
            return []

        if right_time - left_time <= threshold:
            return [{"end": int(right_time), "text": left_text}]

        mid_time = (left_time + right_time) / 2
        mid_text = self.ocr(mid_time)

        return (
            self.binary_segmentation(left_time, mid_time, left_text, mid_text, threshold, sim_threshold)
            + self.binary_segmentation(mid_time, right_time, mid_text, right_text, threshold, sim_threshold)
        )

    def scan_video(self, scan_step=4):
        """Scan video ƒë·ªÉ t√¨m t·∫•t c·∫£ timestamps thay ƒë·ªïi text"""
        video_duration = int(self.total_frames / self.video_fps)
        timestamps = []

        prev_time = 1
        prev_text = self.ocr(prev_time)

        for t in range(scan_step, video_duration + scan_step, scan_step):
            curr_time = min(t, video_duration - 1)
            curr_text = self.ocr(curr_time)

            if curr_text != prev_text:
                change_times = self.binary_segmentation(prev_time, curr_time, prev_text, curr_text)
                timestamps.extend(change_times)

            prev_time = curr_time
            prev_text = curr_text

        return timestamps

    @staticmethod
    def build_segments(timestamps):
        """X√¢y d·ª±ng segments v·ªõi start v√† end time"""
        timestamps_with_start = []
        prev_end = 0.0

        for seg in timestamps:
            start = prev_end
            end = seg['end']
            text = seg['text']
            timestamps_with_start.append({
                "start": start,
                "end": end,
                "text": text
            })
            prev_end = end

        return timestamps_with_start


def serialize_segments(segments):
    output = []

    for i, seg in enumerate(segments):
        start = seg["start"]
        end = seg["end"]
        text = seg.get("text", "")

        output.append({
            "id": i,
            "start": start,
            "end": end,
            "text": text,
        })

    return output


def save_segments_json(segments, json_output="segments.json"):
    output = serialize_segments(segments)

    with open(json_output, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    return output


def _process_single_video(args):
    """
    Wrapper function cho ProcessPoolExecutor.
    Nh·∫≠n tuple (index, title, video_path, base_output_dir, scan_step)
    """
    index, title, video_path, base_output_dir, scan_step = args
    
    video_path = Path(video_path)
    output_dir = Path(base_output_dir) / f"{index:03d}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # D√πng context manager ƒë·ªÉ t·ª± ƒë·ªông cleanup sau khi x·ª≠ l√Ω xong
    with VideoOCRProcessor(str(video_path)) as processor:
        timestamps = processor.scan_video(scan_step=scan_step)
        segments = processor.build_segments(timestamps)

        segments_json = output_dir / f"{index:03d}_segments.json"
        save_segments_json(
            segments=segments,
            json_output=str(segments_json)
        )

        return {
            "index": index,
            "title": title,
            "video_path": str(video_path),
            "segments_json": str(segments_json),
            "segment_count": len(segments),
            "ocr_calls": processor.ocr_calls,
        }


def process_video_item(item: PlaylistItem, base_output_dir: str, scan_step: int = 4):
    return _process_single_video((
        item.index,
        item.title,
        item.video_path,
        base_output_dir,
        scan_step
    ))


def _process_video_worker(video_path: str, scan_step: int, crop, result_queue):
    """Worker ch·∫°y trong subprocess ri√™ng ƒë·ªÉ tr√°nh memory leak"""
    try:
        with VideoOCRProcessor(video_path, crop=crop) as processor:
            timestamps = processor.scan_video(scan_step=scan_step)
            segments = processor.build_segments(timestamps)
        result_queue.put(("success", serialize_segments(segments)))
    except Exception as e:
        result_queue.put(("error", str(e)))


def process_video_to_segments(video_path: str, scan_step: int = 4, crop=None):
    """
    X·ª≠ l√Ω m·ªôt video v√† tr·∫£ v·ªÅ danh s√°ch segments (kh√¥ng l∆∞u file).
    Ch·∫°y trong subprocess ri√™ng ƒë·ªÉ kernel gi·∫£i ph√≥ng ho√†n to√†n memory sau m·ªói request.
    """
    if crop is None:
        crop = (100, 530, 1200, 680)
    
    # Spawn subprocess ƒë·ªÉ x·ª≠ l√Ω video
    # Khi subprocess k·∫øt th√∫c, kernel gi·∫£i ph√≥ng 100% memory (bao g·ªìm Decord/FFmpeg)
    result_queue = mp.Queue()
    p = mp.Process(target=_process_video_worker, args=(video_path, scan_step, crop, result_queue))
    p.start()
    p.join()  # ƒê·ª£i subprocess k·∫øt th√∫c
    
    status, data = result_queue.get()
    if status == "error":
        raise RuntimeError(data)
    
    return data


def _iter_batches(items, batch_size):
    for i in range(0, len(items), batch_size):
        yield items[i:i + batch_size]


def process_playlist_items(
    items,
    base_output_dir: str,
    batch_size: int = 4,
    scan_step: int = 4,
    start_index: int | None = None,
    end_index: int | None = None,
):
    os.makedirs(base_output_dir, exist_ok=True)

    filtered_items = [
        item for item in items
        if (start_index is None or item.index >= start_index)
        and (end_index is None or item.index <= end_index)
    ]

    results = []
    total_batches = (len(filtered_items) + batch_size - 1) // batch_size
    
    for batch_idx, chunk in enumerate(_iter_batches(filtered_items, batch_size), start=1):
        batch_results = []

        task_args = [
            (item.index, item.title, item.video_path, base_output_dir, scan_step)
            for item in chunk
        ]
        
        # M·ªói process khi k·∫øt th√∫c s·∫Ω ƒë∆∞·ª£c kernel gi·∫£i ph√≥ng TO√ÄN B·ªò memory
        with ProcessPoolExecutor(max_workers=len(chunk)) as executor:
            future_map = {
                executor.submit(_process_single_video, args): args
                for args in task_args
            }
            for future in as_completed(future_map):
                args = future_map[future]
                index, title = args[0], args[1]
                try:
                    result = future.result()
                    print(f"‚úì Processed #{index:03d}: {title}")
                    results.append(result)
                    batch_results.append(result)
                except Exception as exc:
                    print(f"‚úó Failed #{index:03d}: {title} -> {exc}")
        
        # Print k·∫øt qu·∫£ sau m·ªói batch
        if batch_results:
            print("\n" + "‚îÄ" * 60)
            print(f"üì¶ BATCH {batch_idx}/{total_batches} HO√ÄN TH√ÄNH ({len(batch_results)}/{len(chunk)} th√†nh c√¥ng)")
            sample = batch_results[0]
            print(f"   Sample: #{sample['index']:03d} - {sample['title']}")
            print(f"           Segments: {sample['segment_count']} | OCR calls: {sample['ocr_calls']}")
            print(f"           JSON: {sample['segments_json']}")
            print(f"   T·ªïng ƒë√£ x·ª≠ l√Ω: {len(results)}/{len(filtered_items)} video")
            print("‚îÄ" * 60 + "\n")
        
        gc.collect()
    return sorted(results, key=lambda item: item['index'])


def scan_video_directory(video_dir: str):
    """
    Scan th∆∞ m·ª•c video v√† t·∫°o danh s√°ch PlaylistItem
    """
    video_dir_path = Path(video_dir)
    if not video_dir_path.exists():
        raise ValueError(f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {video_dir}")
    
    video_extensions = ['.mp4']
    video_files = []
    
    for ext in video_extensions:
        video_files.extend(video_dir_path.glob(f"*{ext}"))
    
    video_files.sort()
    
    playlist_items = []
    for idx, video_path in enumerate(video_files, start=1):
        title = video_path.stem
        playlist_items.append(PlaylistItem(
            index=idx,
            title=title,
            video_path=str(video_path)
        ))
    
    return playlist_items


if __name__ == "__main__":
    VIDEO_INPUT_DIR = os.getenv(
        "VIDEO_INPUT_DIR",
        "/home/app/cuonglp1/speech_topic/data/raw",
    )
    
    PROCESSING_OUTPUT_DIR = os.getenv(
        "PROCESSING_OUTPUT_DIR",
        "/home/app/cuonglp1/speech_topic/data/processed_final",
    )
    
    # C√°c tham s·ªë x·ª≠ l√Ω
    BATCH_SIZE = 1          # S·ªë video x·ª≠ l√Ω song song
    SCAN_STEP = 4           # B∆∞·ªõc nh·∫£y khi scan video (gi√¢y)
    START_INDEX = None      # Index video ƒë·∫ßu ti√™n c·∫ßn x·ª≠ l√Ω (None = t·ª´ ƒë·∫ßu)
    END_INDEX = None        # Index video cu·ªëi c√πng c·∫ßn x·ª≠ l√Ω (None = ƒë·∫øn h·∫øt)

    # Scan th∆∞ m·ª•c video
    print(f"\nüìÇ ƒêang scan th∆∞ m·ª•c: {VIDEO_INPUT_DIR}")
    playlist_items = scan_video_directory(VIDEO_INPUT_DIR)
    print(f"‚úì T√¨m th·∫•y {len(playlist_items)} video")
    
    if not playlist_items:
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y video n√†o trong th∆∞ m·ª•c!")
        exit(1)
    
    # Hi·ªÉn th·ªã danh s√°ch video
    print("\n Danh s√°ch video:")
    for item in playlist_items[:5]:  # Hi·ªÉn th·ªã 5 video ƒë·∫ßu ti√™n
        print(f"  #{item.index:03d}: {item.title}")
    if len(playlist_items) > 5:
        print(f"  ... v√† {len(playlist_items) - 5} video kh√°c")
    
    # X·ª≠ l√Ω video
    print(f"\n  B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video...")
    print(f"  - Output directory: {PROCESSING_OUTPUT_DIR}")
    print(f"  - Batch size: {BATCH_SIZE}")
    print(f"  - Scan step: {SCAN_STEP}s")
    print(f"  - Index range: {START_INDEX or 'start'} ‚Üí {END_INDEX or 'end'}")
    
    processing_results = process_playlist_items(
        playlist_items,
        base_output_dir=PROCESSING_OUTPUT_DIR,
        batch_size=BATCH_SIZE,
        scan_step=SCAN_STEP,
        start_index=START_INDEX,
        end_index=END_INDEX,
    )

