{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-21T03:36:49.614379Z",
     "iopub.status.busy": "2025-11-21T03:36:49.613971Z",
     "iopub.status.idle": "2025-11-21T03:37:01.911712Z",
     "shell.execute_reply": "2025-11-21T03:37:01.910326Z",
     "shell.execute_reply.started": "2025-11-21T03:36:49.614350Z"
    },
    "executionInfo": {
     "elapsed": 13288,
     "status": "ok",
     "timestamp": 1763631377754,
     "user": {
      "displayName": "Cuong",
      "userId": "04503431726301456561"
     },
     "user_tz": -420
    },
    "id": "GR1wlfyApE7-",
    "outputId": "3cf1d835-d843-4931-c7c6-7f19fb953188",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.0/473.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.7 which is incompatible.\n",
      "langchain-text-splitters 0.3.9 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q yt-dlp decord langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T03:37:01.913900Z",
     "iopub.status.busy": "2025-11-21T03:37:01.913595Z",
     "iopub.status.idle": "2025-11-21T03:37:04.492936Z",
     "shell.execute_reply": "2025-11-21T03:37:04.491745Z",
     "shell.execute_reply.started": "2025-11-21T03:37:01.913870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1sq86cC0oBBLLcz1T4YTXEkL4PwmTm6tu\n",
      "To: /kaggle/working/cookies.txt\n",
      "100%|████████████████████████████████████████| 797k/797k [00:00<00:00, 88.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1sq86cC0oBBLLcz1T4YTXEkL4PwmTm6tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T03:37:04.494694Z",
     "iopub.status.busy": "2025-11-21T03:37:04.494382Z",
     "iopub.status.idle": "2025-11-21T03:37:10.486908Z",
     "shell.execute_reply": "2025-11-21T03:37:10.485551Z",
     "shell.execute_reply.started": "2025-11-21T03:37:04.494653Z"
    },
    "id": "Icsl_hJW_dD0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import subprocess\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "def extract_audio_from_mp4(video_path, output_audio_path):\n",
    "  try:\n",
    "      command = [\n",
    "          'ffmpeg',\n",
    "          '-i', video_path,           # Input video\n",
    "          '-vn',                       # Không lấy video\n",
    "          '-acodec', 'libmp3lame',    # Codec MP3\n",
    "          '-q:a', '2',                 # Chất lượng audio (0-9, 2 là tốt)\n",
    "          '-y',                        # Overwrite nếu file đã tồn tại\n",
    "          output_audio_path\n",
    "      ]\n",
    "\n",
    "      subprocess.run(command, check=True, capture_output=True)\n",
    "      print(f\"✓ Đã tách audio: {output_audio_path}\")\n",
    "      return True\n",
    "  except subprocess.CalledProcessError as e:\n",
    "      print(f\"✗ Lỗi khi tách audio: {e}\")\n",
    "      return False\n",
    "\n",
    "\n",
    "def download_and_extract_audio(video_path, output_name):\n",
    "  \"\"\"\n",
    "  video_path: link video\n",
    "  \"\"\"\n",
    "  video_file = f\"{output_name}.mp4\"\n",
    "  audio_file = f\"{output_name}.mp3\"\n",
    "\n",
    "  ydl_opts = {\n",
    "    'format': 'best[ext=mp4]',\n",
    "    'outtmpl': video_file,\n",
    "    'cookiefile': '/kaggle/working/cookies.txt',\n",
    "  }\n",
    "\n",
    "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([ytb_path])\n",
    "\n",
    "  extract_audio_from_mp4(video_file, audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T03:37:10.489766Z",
     "iopub.status.busy": "2025-11-21T03:37:10.489255Z",
     "iopub.status.idle": "2025-11-21T03:37:10.508573Z",
     "shell.execute_reply": "2025-11-21T03:37:10.507504Z",
     "shell.execute_reply.started": "2025-11-21T03:37:10.489737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Iterable, Sequence\n",
    "\n",
    "def _iter_batches(items, batch_size):\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        yield items[i:i + batch_size]\n",
    "\n",
    "\n",
    "def _playlist_items_arg(start_index: int | None, end_index: int | None) -> str | None:\n",
    "    \"\"\"Build yt-dlp playlist_items string from start/end index.\"\"\"\n",
    "    if start_index is None and end_index is None:\n",
    "        return None\n",
    "    start = start_index if start_index is not None else 1\n",
    "    if end_index is None:\n",
    "        return f\"{start}-\"\n",
    "    return f\"{start}-{end_index}\"\n",
    "\n",
    "\n",
    "def _build_playlist_opts(output_dir: str, subtitle_langs: Sequence[str], playlist_items: str | None = None) -> dict:\n",
    "    opts = {\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'merge_output_format': 'mp4',\n",
    "        'writesubtitles': True,\n",
    "        'writeautomaticsub': True,\n",
    "        'subtitleslangs': list(subtitle_langs),\n",
    "        'subtitlesformat': 'vtt',\n",
    "        'ignoreerrors': True,\n",
    "        'cookiefile': '/kaggle/working/cookies.txt',\n",
    "        'paths': {\n",
    "            'home': output_dir,\n",
    "            'temp': output_dir,\n",
    "        }\n",
    "    }\n",
    "    if playlist_items:\n",
    "        opts['playlist_items'] = playlist_items\n",
    "    return opts\n",
    "\n",
    "\n",
    "def _download_playlist_entry(entry: dict, base_opts: dict, output_dir: str):\n",
    "    idx = int(entry['playlist_index']) if entry.get('playlist_index') else 0\n",
    "    opts = base_opts.copy()\n",
    "    opts['outtmpl'] = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{idx:03d} - %(title)s.%(ext)s\"\n",
    "    )\n",
    "\n",
    "    filepath = None\n",
    "    with yt_dlp.YoutubeDL(opts) as ydl:\n",
    "        info = ydl.extract_info(entry['webpage_url'], download=True)\n",
    "        filepath = ydl.prepare_filename(info)\n",
    "        merge_ext = opts.get('merge_output_format')\n",
    "        if merge_ext:\n",
    "            filepath = os.path.splitext(filepath)[0] + f\".{merge_ext}\"\n",
    "\n",
    "    return idx, entry.get('title', 'unknown title'), filepath\n",
    "\n",
    "\n",
    "def download_playlist_batch(\n",
    "    playlist_url: str,\n",
    "    output_dir: str = '/kaggle/working/playlist_downloads',\n",
    "    subtitle_langs: Sequence[str] = ('vi',),\n",
    "    batch_size: int = 4,\n",
    "    start_index: int | None = None,\n",
    "    end_index: int | None = None,\n",
    "):\n",
    "    \"\"\"Download a YouTube playlist in sequential batches (default batch size 4).\"\"\"\n",
    "    if batch_size < 1:\n",
    "        raise ValueError('batch_size must be >= 1')\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Build playlist_items filter\n",
    "    items_filter = _playlist_items_arg(start_index, end_index)\n",
    "    \n",
    "    # Fetch playlist metadata without downloading first\n",
    "    metadata_opts = {\n",
    "        'ignoreerrors': True,\n",
    "        'cookiefile': '/kaggle/working/cookies.txt',\n",
    "    }\n",
    "    if items_filter:\n",
    "        metadata_opts['playlist_items'] = items_filter\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(metadata_opts) as ydl:\n",
    "        playlist_info = ydl.extract_info(playlist_url, download=False)\n",
    "\n",
    "    entries: Iterable[dict] = playlist_info.get('entries', [])\n",
    "    filtered_entries = []\n",
    "    fallback_index = start_index if start_index is not None else 1\n",
    "    for entry in entries:\n",
    "        if not entry:\n",
    "            fallback_index += 1\n",
    "            continue\n",
    "        if entry.get('playlist_index') is None:\n",
    "            entry['playlist_index'] = fallback_index\n",
    "        filtered_entries.append(entry)\n",
    "        fallback_index += 1\n",
    "\n",
    "    base_opts = _build_playlist_opts(output_dir, subtitle_langs, items_filter)\n",
    "\n",
    "    results = []\n",
    "    for chunk in _iter_batches(filtered_entries, batch_size):\n",
    "        with ThreadPoolExecutor(max_workers=len(chunk)) as executor:\n",
    "            future_map = {\n",
    "                executor.submit(_download_playlist_entry, entry, base_opts, output_dir): entry\n",
    "                for entry in chunk\n",
    "            }\n",
    "            for future in as_completed(future_map):\n",
    "                entry = future_map[future]\n",
    "                try:\n",
    "                    idx, title, video_path = future.result()\n",
    "                    print(f\"✓ Downloaded #{idx:03d}: {title}\")\n",
    "                    results.append({'index': idx, 'title': title, 'video_path': video_path})\n",
    "                except Exception as exc:\n",
    "                    print(f\"✗ Failed #{entry.get('playlist_index')}: {entry.get('title')} -> {exc}\")\n",
    "\n",
    "    return sorted(results, key=lambda item: item['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T03:37:10.509968Z",
     "iopub.status.busy": "2025-11-21T03:37:10.509603Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "playlist_url = \"https://www.youtube.com/playlist?list=PLM1poDh0i5QS8klF38_bHsXmZS4smbHse\"\n",
    "playlist_output_dir = \"/kaggle/working/playlist_downloads\"\n",
    "subtitle_langs = (\"vi\",)\n",
    "batch_size = 4\n",
    "start_index = 10   # chỉ số video đầu tiên muốn tải (None nếu bỏ qua)\n",
    "end_index = 40  # chỉ số video cuối muốn tải (None để tới hết playlist)\n",
    "\n",
    "summary = download_playlist_batch(\n",
    "    playlist_url,\n",
    "    output_dir=playlist_output_dir,\n",
    "    subtitle_langs=subtitle_langs,\n",
    "    batch_size=batch_size,\n",
    "    start_index=start_index,\n",
    "    end_index=end_index,\n",
    ")\n",
    "\n",
    "if summary:\n",
    "    download_first = summary[0]['index']\n",
    "    download_last = summary[-1]['index']\n",
    "else:\n",
    "    download_first = start_index if start_index is not None else \"-\"\n",
    "    download_last = end_index if end_index is not None else \"-\"\n",
    "\n",
    "print(\n",
    "    f\"\\nĐã tải {len(summary)} video (index {download_first}→{download_last})\"\n",
    "    f\" vào thư mục {playlist_output_dir}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48558,
     "status": "ok",
     "timestamp": 1763630468026,
     "user": {
      "displayName": "Hoàng Hưng",
      "userId": "17936511279045817563"
     },
     "user_tz": -420
    },
    "id": "Akl28kbrE3F9",
    "outputId": "97bdc5e9-c683-4a2a-d19a-f6f336430a14",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import unicodedata\n",
    "from difflib import SequenceMatcher\n",
    "import base64\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from decord import VideoReader, cpu\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from httpx import Client\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PlaylistItem:\n",
    "    index: int\n",
    "    title: str\n",
    "    video_path: str\n",
    "\n",
    "\n",
    "def normalized(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "\n",
    "    s = text.strip()\n",
    "    s = s.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.lower()\n",
    "    s = s.replace(' - ', '-')\n",
    "\n",
    "    s = unicodedata.normalize('NFD', s)\n",
    "    s = ''.join(char for char in s if unicodedata.category(char) != 'Mn')\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def is_similar_text(a, b, sim_threshold=0.85):\n",
    "    na, nb = normalized(a), normalized(b)\n",
    "    if na == \"\" and nb == \"\":\n",
    "        return True\n",
    "    sim = similarity(na, nb)\n",
    "    return sim >= sim_threshold\n",
    "\n",
    "\n",
    "def numpy_to_base64(img: np.ndarray) -> str:\n",
    "    _, buffer = cv2.imencode(\".png\", img)\n",
    "    img_bytes = buffer.tobytes()\n",
    "    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "    return img_b64\n",
    "\n",
    "\n",
    "def get_fpt_llm(temperature=0.0):\n",
    "    client = Client(verify=False)\n",
    "    return ChatOpenAI(\n",
    "        model=\"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "        openai_api_base=\"https://my-container-4voix9lz-8000.serverless.fptcloud.com/v1\",\n",
    "        openai_api_key=\"your_api_key\",\n",
    "        http_client=client,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "\n",
    "llm = get_fpt_llm()\n",
    "\n",
    "\n",
    "class VideoOCRProcessor:\n",
    "    def __init__(self, video_path: str, crop=(100, 530, 1200, 680)):\n",
    "        self.video_path = video_path\n",
    "        self.crop = crop\n",
    "        self.vr = VideoReader(video_path, ctx=cpu(0))\n",
    "        self.total_frames = len(self.vr)\n",
    "        self.video_fps = float(self.vr.get_avg_fps())\n",
    "        self.ocr_calls = 0\n",
    "        self.ocr_cache = {}\n",
    "\n",
    "    def read_frame(self, time_point: float):\n",
    "        frame_index = int(time_point * self.video_fps) + 1\n",
    "        frame_index = min(frame_index, self.total_frames - 1)\n",
    "\n",
    "        if frame_index < 0 or frame_index >= self.total_frames:\n",
    "            return None\n",
    "\n",
    "        frame = self.vr[frame_index].asnumpy()\n",
    "        x1, y1, x2, y2 = self.crop\n",
    "        return frame[y1:y2, x1:x2]\n",
    "\n",
    "    def ocr_with_fpt(self, frame_time: float):\n",
    "        if frame_time in self.ocr_cache:\n",
    "            return self.ocr_cache[frame_time]\n",
    "\n",
    "        frame = self.read_frame(frame_time)\n",
    "        if frame is None:\n",
    "            return \"\"\n",
    "\n",
    "        self.ocr_calls += 1\n",
    "        img_b64 = numpy_to_base64(frame)\n",
    "\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Hãy đọc OCR trong ảnh này, trả về text đúng nhất. Chỉ trả về text, không giải thích thêm. Nếu trong ảnh không có text hoặc không đọc được ocr thì trả về \"\". Nếu trong ảnh có phần bảng tên của người phỏng vấn thì cũng không trả về text ở trong đó.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{img_b64}\"},\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response = llm.invoke([message])\n",
    "        text = response.content\n",
    "        self.ocr_cache[frame_time] = text\n",
    "        return text\n",
    "\n",
    "    def binary_segmentation(self, left_time, right_time, left_text=None, right_text=None, threshold=0.5, sim_threshold=0.9):\n",
    "        if left_text is None:\n",
    "            left_text = self.ocr_with_fpt(left_time)\n",
    "        if right_text is None:\n",
    "            right_text = self.ocr_with_fpt(right_time)\n",
    "\n",
    "        if is_similar_text(left_text, right_text, sim_threshold):\n",
    "            return []\n",
    "\n",
    "        if right_time - left_time <= threshold:\n",
    "            return [{\"end\": int(right_time), \"text\": left_text}]\n",
    "\n",
    "        mid_time = (left_time + right_time) / 2\n",
    "        mid_text = self.ocr_with_fpt(mid_time)\n",
    "\n",
    "        return (\n",
    "            self.binary_segmentation(left_time, mid_time, left_text, mid_text, threshold, sim_threshold)\n",
    "            + self.binary_segmentation(mid_time, right_time, mid_text, right_text, threshold, sim_threshold)\n",
    "        )\n",
    "\n",
    "    def scan_video(self, scan_step=4):\n",
    "        video_duration = int(self.total_frames / self.video_fps)\n",
    "        timestamps = []\n",
    "\n",
    "        prev_time = 1\n",
    "        prev_text = self.ocr_with_fpt(prev_time)\n",
    "\n",
    "        for t in range(scan_step, video_duration + scan_step, scan_step):\n",
    "            curr_time = min(t, video_duration - 1)\n",
    "            curr_text = self.ocr_with_fpt(curr_time)\n",
    "\n",
    "            if curr_text != prev_text:\n",
    "                change_times = self.binary_segmentation(prev_time, curr_time, prev_text, curr_text)\n",
    "                timestamps.extend(change_times)\n",
    "\n",
    "            prev_time = curr_time\n",
    "            prev_text = curr_text\n",
    "\n",
    "        return timestamps\n",
    "\n",
    "    @staticmethod\n",
    "    def build_segments(timestamps):\n",
    "        timestamps_with_start = []\n",
    "        prev_end = 0.0\n",
    "\n",
    "        for seg in timestamps:\n",
    "            start = prev_end\n",
    "            end = seg['end']\n",
    "            text = seg['text']\n",
    "            timestamps_with_start.append({\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"text\": text\n",
    "            })\n",
    "            prev_end = end\n",
    "\n",
    "        return timestamps_with_start\n",
    "\n",
    "\n",
    "def cut_audio_segments(\n",
    "    input_audio_path,\n",
    "    segments,\n",
    "    output_folder=\"audio_segments\",\n",
    "    json_output=\"segments.json\"\n",
    "):\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for i, seg in enumerate(segments):\n",
    "        start = seg[\"start\"]\n",
    "        end = seg[\"end\"]\n",
    "        text = seg.get(\"text\", \"\")\n",
    "\n",
    "        duration = end - start\n",
    "        audio_path = os.path.join(output_folder, f\"{i}.wav\")\n",
    "\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-i\", input_audio_path,\n",
    "            \"-ss\", str(start),\n",
    "            \"-t\", str(duration),\n",
    "            audio_path\n",
    "        ]\n",
    "\n",
    "        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        output.append({\n",
    "            \"id\": i,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"text\": text,\n",
    "            \"audio_path\": audio_path\n",
    "        })\n",
    "\n",
    "    with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def process_video_item(item: PlaylistItem, base_output_dir: str, scan_step: int = 4):\n",
    "    video_path = Path(item.video_path)\n",
    "    output_dir = Path(base_output_dir) / f\"{item.index:03d}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    audio_path = output_dir / f\"{item.index:03d}.mp3\"\n",
    "    extract_audio_from_mp4(str(video_path), str(audio_path))\n",
    "\n",
    "    processor = VideoOCRProcessor(str(video_path))\n",
    "    timestamps = processor.scan_video(scan_step=scan_step)\n",
    "    segments = processor.build_segments(timestamps)\n",
    "\n",
    "    segments_folder = output_dir / \"audio_segments\"\n",
    "    segments_json = output_dir / f\"{item.index:03d}_segments.json\"\n",
    "    cut_audio_segments(\n",
    "        input_audio_path=str(audio_path),\n",
    "        segments=segments,\n",
    "        output_folder=str(segments_folder),\n",
    "        json_output=str(segments_json)\n",
    "    )\n",
    "\n",
    "    zip_path = shutil.make_archive(str(segments_folder), 'zip', str(segments_folder))\n",
    "\n",
    "    return {\n",
    "        \"index\": item.index,\n",
    "        \"title\": item.title,\n",
    "        \"video_path\": str(video_path),\n",
    "        \"audio_path\": str(audio_path),\n",
    "        \"segments_json\": str(segments_json),\n",
    "        \"segments_zip\": zip_path,\n",
    "        \"segment_count\": len(segments),\n",
    "        \"ocr_calls\": processor.ocr_calls,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_playlist_items(\n",
    "    items,\n",
    "    base_output_dir: str,\n",
    "    batch_size: int = 4,\n",
    "    scan_step: int = 4,\n",
    "    start_index: int | None = None,\n",
    "    end_index: int | None = None,\n",
    "):\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    filtered_items = [\n",
    "        item for item in items\n",
    "        if (start_index is None or item.index >= start_index)\n",
    "        and (end_index is None or item.index <= end_index)\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for chunk in _iter_batches(filtered_items, batch_size):\n",
    "        with ThreadPoolExecutor(max_workers=len(chunk)) as executor:\n",
    "            future_map = {\n",
    "                executor.submit(process_video_item, item, base_output_dir, scan_step): item\n",
    "                for item in chunk\n",
    "            }\n",
    "            for future in as_completed(future_map):\n",
    "                item = future_map[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    print(f\"✓ Processed #{item.index:03d}: {item.title}\")\n",
    "                    results.append(result)\n",
    "                except Exception as exc:\n",
    "                    print(f\"✗ Failed #{item.index:03d}: {item.title} -> {exc}\")\n",
    "\n",
    "    return sorted(results, key=lambda item: item['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9992,
     "status": "ok",
     "timestamp": 1763637458838,
     "user": {
      "displayName": "Hoàng Hưng",
      "userId": "17936511279045817563"
     },
     "user_tz": -420
    },
    "id": "VCEZQXpVFiRz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "playlist_items = [\n",
    "    PlaylistItem(index=item['index'], title=item['title'], video_path=item['video_path'])\n",
    "    for item in summary\n",
    "]\n",
    "\n",
    "print(f\"Tổng số video cần xử lý: {len(playlist_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1763637458840,
     "user": {
      "displayName": "Hoàng Hưng",
      "userId": "17936511279045817563"
     },
     "user_tz": -420
    },
    "id": "GBIzV_qbSGnx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "processing_output_dir = \"/kaggle/working/playlist_processed\"\n",
    "scan_step = 4\n",
    "\n",
    "processing_results = process_playlist_items(\n",
    "    playlist_items,\n",
    "    base_output_dir=processing_output_dir,\n",
    "    batch_size=batch_size,\n",
    "    scan_step=scan_step,\n",
    "    start_index=start_index,\n",
    "    end_index=end_index,\n",
    ")\n",
    "\n",
    "if processing_results:\n",
    "    processed_first = processing_results[0]['index']\n",
    "    processed_last = processing_results[-1]['index']\n",
    "else:\n",
    "    processed_first = start_index if start_index is not None else \"-\"\n",
    "    processed_last = end_index if end_index is not None else \"-\"\n",
    "\n",
    "print(\n",
    "    f\"\\nHoàn tất xử lý {len(processing_results)} video (index {processed_first}→{processed_last})\"\n",
    "    f\" và lưu tại {processing_output_dir}\"\n",
    ")\n",
    "for item in processing_results[:3]:\n",
    "    print(f\"#{item['index']:03d} | segments: {item['segment_count']} | json: {item['segments_json']}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
