{
  "model": "Qwen/Qwen2.5-VL-3B-Instruct",
  "disable_log_stats": false,
  "gpu_memory_utilization": 0.25,
  "max_model_len": 16384,
  "dtype": "auto",
  "quantization": "fp8",
  "enforce_eager": false,
  "max_num_seqs": 256,
  "tensor_parallel_size": 1,
  "pipeline_parallel_size": 1,
  "trust_remote_code": true,
  "enable_lora": false,
  "max_lora_rank": 16,
  "enable_prefix_caching": true,
  "disable_sliding_window": false
}
